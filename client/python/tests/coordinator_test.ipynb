{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Connecting to Presto\n",
    "\n",
    "Presto ships with a CLI which supports autocompletion, history, progress bars and other useful features. For quickly testing queries the CLI is very helpful.\n",
    "\n",
    "In a environment like a Jupyter notebook, we can use a Presto Python client. The Presto client library implements the Python DBAPI2.0 interface that is used by common database client libraries for querying MySQL, PostgreSQL and SQLite.\n",
    "\n",
    "DBAPI2.0 defines a API with a `Connection`. Queries then happen with a `cursor`. Presto supports transaction. The level of isolation depends on the connectors involved in a query.\n",
    "\n",
    "The three mandatory arguments to create a connection are *host*, *port*, and *user*.\n",
    "Other arguments such as *source* allow to identify the origin of the query. A common use case is to use it to tell which service, tool, or code sent the query.\n",
    "\n",
    "Let's create a connection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<prestodb.dbapi.Cursor at 0x7f571125db70>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import prestodb.dbapi as presto\n",
    "\n",
    "conn = presto.Connection(host=\"localhost\", port=8080, user=\"johnsnow\")\n",
    "cur = conn.cursor()\n",
    "cur"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configuration\n",
    "\n",
    "Presto's general configuration is documented in the [deployment](https://prestodb.github.io/docs/current/installation/deployment.html) page. There are 4 types of configuration files:\n",
    "- Node Properties: to configure the coordinator (main server) and worker nodes.\n",
    "- JVM Config: command line options for the Java Virtual Machine that runs Presto.\n",
    "- Config Properties: configuration for the Presto server\n",
    "- Catalog Properties: configuration for Connectors (data sources)\n",
    "\n",
    "In the test, the configuration is in `coordinator/presto/etc/`. The main file to configure Presto is `config.properties`:\n",
    "\n",
    "```\n",
    "node.id=presto-master\n",
    "node.environment=test\n",
    "\n",
    "coordinator=true\n",
    "node-scheduler.include-coordinator=true\n",
    "http-server.http.port=8080\n",
    "query.max-memory=256MB\n",
    "query.max-memory-per-node=256MB\n",
    "discovery-server.enabled=true\n",
    "discovery.uri=http://localhost:8080\n",
    "```\n",
    "\n",
    "The discovery is what allows worker nodes to find the coordinator and register themselves. Then they will participate in the execution of queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Catalogs\n",
    "\n",
    "A catalog is mapped to a connector. The name of configuration file for a catalgo defines the catalog's name. Here `etc/catalog/timescaledb.properties` configures the `timescaledb` catalog. We could name it `events` or `users`:\n",
    "\n",
    "```\n",
    "connector.name=postgresql\n",
    "connection-url=jdbc:postgresql://localhost:5433/db1\n",
    "connection-user=johnsnow\n",
    "connection-password=password\n",
    "```\n",
    "\n",
    "Adding a catalog is a simple as adding a file with the catalog properties and named after the catalog's name.\n",
    "\n",
    "\n",
    "Below we list the available catalogs on the Presto cluster we are running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[['blackhole'],\n ['jmx'],\n ['memory'],\n ['system'],\n ['timescaledb'],\n ['tpcds'],\n ['tpch']]"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"SHOW catalogs\")\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## How Does Presto Execute a Query?\n",
    "\n",
    "If you are curious about what Presto translate a SQL query to and what it will run, you can you `EXPLAIN`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Fragment 0 [SINGLE]\n    Output layout: [id, field1]\n    Output partitioning: SINGLE []\n    Stage Execution Strategy: UNGROUPED_EXECUTION\n    - Output[id, field1] => [id:varchar, field1:varchar]\n            Estimates: {rows: ? (?), cpu: ?, memory: 0.00, network: ?}\n        - RemoteSource[1] => [id:varchar, field1:varchar]\n\nFragment 1 [SOURCE]\n    Output layout: [id, field1]\n    Output partitioning: SINGLE []\n    Stage Execution Strategy: UNGROUPED_EXECUTION\n    - TableScan[TableHandle {connectorId='timescaledb', connectorHandle='timescaledb:public.table1:null:public:table1', layout='Optional[timescaledb:public.table1:null:public:table1]'}, grouped = false] => [id:varchar, field1:varchar]\n            Estimates: {rows: ? (?), cpu: ?, memory: 0.00, network: 0.00}\n            id := JdbcColumnHandle{connectorId=timescaledb, columnName=id, jdbcTypeHandle=JdbcTypeHandle{jdbcType=12, columnSize=2147483647, decimalDigits=0}, columnType=varchar, nullable=false}\n            field1 := JdbcColumnHandle{connectorId=timescaledb, columnName=field1, jdbcTypeHandle=JdbcTypeHandle{jdbcType=12, columnSize=2147483647, decimalDigits=0}, columnType=varchar, nullable=true}\n\n\n"
    }
   ],
   "source": [
    "conn = presto.Connection(host=\"localhost\", port=8080, user=\"johnsnow\", catalog=\"timescaledb\", schema=\"default\")\n",
    "cur.execute(\"explain (type DISTRIBUTED) SELECT * FROM timescaledb.public.table1\")\n",
    "plan = cur.fetchall()\n",
    "\n",
    "print(plan[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "```\n",
    "Fragment 0 [SINGLE]\n",
    "    Output layout: [id, field1]\n",
    "    Output partitioning: SINGLE []\n",
    "    Stage Execution Strategy: UNGROUPED_EXECUTION\n",
    "    - Output[id, field1] => [id:varchar, field1:varchar]\n",
    "            Estimates: {rows: ? (?), cpu: ?, memory: 0.00, network: ?}\n",
    "        - RemoteSource[1] => [id:varchar, field1:varchar]\n",
    "\n",
    "Fragment 1 [SOURCE]\n",
    "    Output layout: [id, field1]\n",
    "    Output partitioning: SINGLE []\n",
    "    Stage Execution Strategy: UNGROUPED_EXECUTION\n",
    "    - TableScan[TableHandle {connectorId='timescaledb', connectorHandle='timescaledb:public.table1:null:public:table1', layout='Optional[timescaledb:public.table1:null:public:table1]'}, grouped = false] => [id:varchar, field1:varchar]\n",
    "            Estimates: {rows: ? (?), cpu: ?, memory: 0.00, network: 0.00}\n",
    "            id := JdbcColumnHandle{connectorId=timescaledb, columnName=id, jdbcTypeHandle=JdbcTypeHandle{jdbcType=12, columnSize=2147483647, decimalDigits=0}, columnType=varchar, nullable=false}\n",
    "            field1 := JdbcColumnHandle{connectorId=timescaledb, columnName=field1, jdbcTypeHandle=JdbcTypeHandle{jdbcType=12, columnSize=2147483647, decimalDigits=0}, columnType=varchar, nullable=true}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "- Output[id, field1] => [id:varchar, field1:varchar]\n        Estimates: {rows: ? (?), cpu: ?, memory: 0.00, network: ?}\n    - RemoteStreamingExchange[GATHER] => [id:varchar, field1:varchar]\n            Estimates: {rows: ? (?), cpu: ?, memory: 0.00, network: ?}\n        - TableScan[TableHandle {connectorId='timescaledb', connectorHandle='timescaledb:public.table1:null:public:table1', layout='Optional[timescaledb:public.table1:null:public:table1]'}] => [id:varchar, field1:varchar]\n                Estimates: {rows: ? (?), cpu: ?, memory: 0.00, network: 0.00}\n                id := JdbcColumnHandle{connectorId=timescaledb, columnName=id, jdbcTypeHandle=JdbcTypeHandle{jdbcType=12, columnSize=2147483647, decimalDigits=0}, columnType=varchar, nullable=false}\n                field1 := JdbcColumnHandle{connectorId=timescaledb, columnName=field1, jdbcTypeHandle=JdbcTypeHandle{jdbcType=12, columnSize=2147483647, decimalDigits=0}, columnType=varchar, nullable=true}\n\n"
    }
   ],
   "source": [
    "cur.execute(\"explain SELECT * FROM timescaledb.public.table1\")\n",
    "plan = cur.fetchall()\n",
    "\n",
    "print(plan[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "```\n",
    "- Output[id, field1] => [id:varchar, field1:varchar]\n",
    "        Estimates: {rows: ? (?), cpu: ?, memory: 0.00, network: ?}\n",
    "    - RemoteStreamingExchange[GATHER] => [id:varchar, field1:varchar]\n",
    "            Estimates: {rows: ? (?), cpu: ?, memory: 0.00, network: ?}\n",
    "        - TableScan[TableHandle {connectorId='timescaledb', connectorHandle='timescaledb:public.table1:null:public:table1', layout='Optional[timescaledb:public.table1:null:public:table1]'}] => [id:varchar, field1:varchar]\n",
    "                Estimates: {rows: ? (?), cpu: ?, memory: 0.00, network: 0.00}\n",
    "                id := JdbcColumnHandle{connectorId=timescaledb, columnName=id, jdbcTypeHandle=JdbcTypeHandle{jdbcType=12, columnSize=2147483647, decimalDigits=0}, columnType=varchar, nullable=false}\n",
    "                field1 := JdbcColumnHandle{connectorId=timescaledb, columnName=field1, jdbcTypeHandle=JdbcTypeHandle{jdbcType=12, columnSize=2147483647, decimalDigits=0}, columnType=varchar, nullable=true}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a Table in TimeScaleDB\n",
    "\n",
    "Let's use the TimeScaleDB client to create the table. Then we will switch to Presto to manipulate the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "event: [varchar(1000000), , ]\n"
    }
   ],
   "source": [
    "cur.execute(\"CREATE TABLE IF NOT EXISTS timescaledb.public.ts_events (event varchar(1000000))\")\n",
    "cur.fetchall()\n",
    "cur.execute(\"DESC timescaledb.public.ts_events\")\n",
    "for row in cur.fetchall():\n",
    "    print(\"{table}: [{props}]\".format(\n",
    "        table=row[0],\n",
    "        props=', '.join(str(i) for i in row[1:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Data in TimeScaleDB\n",
    "\n",
    "Let's now load data from [GH Archive](http://www.gharchive.org/) into TimeScaleDB.\n",
    "Each file from GH Archive contains lines of JSON structs that represent events from the public GitHub timeline, for example repository creation or code push.\n",
    "\n",
    "Now that the table is create in TimeScaleDB, we can insert rows with Presto by using the existing `conn` object created above. You can open http://localhost:8080 to see the execution Presto queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import io\n",
    "import json\n",
    "import re\n",
    "import requests\n",
    "\n",
    "# Load events happening between 4-5pm.\n",
    "# Feel free to load more hours or more days.\n",
    "# We limit the dataset to one hour here to not overload\n",
    "# the machine that will run the queries as this tutorial\n",
    "# is expected to run on a laptop.\n",
    "# It is going to take some time. For the demo, i pre-loaded\n",
    "# the data with the mysql client to avoid the overhead of creating\n",
    "# Python objects.\n",
    "zdata = requests.get(\"https://data.gharchive.org/2015-04-28-16.json.gz\")\n",
    "data = gzip.decompress(zdata.content)\n",
    "rows = []\n",
    "\n",
    "# load ``ROW_COUNT`` rows. Feel free to set a greater value if it\n",
    "# works well in your environment. Using a small value on purpose\n",
    "# to avoid loading data for a long time.\n",
    "ROW_COUNT = 1000\n",
    "cur = conn.cursor()\n",
    "for n, line in enumerate(io.BytesIO(data)):\n",
    "    row = line.strip().decode('utf8')\n",
    "    sql = \"INSERT INTO timescaledb.public.ts_events (event) VALUES ('{}')\".format(row.replace(\"'\", \"''\"))\n",
    "    cur.execute(sql)\n",
    "    cur.fetchall()\n",
    "    if n == ROW_COUNT - 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "{\n    \"actor\": {\n        \"avatar_url\": \"https://avatars.githubusercontent.com/u/126762?\",\n        \"gravatar_id\": \"\",\n        \"id\": 126762,\n        \"login\": \"seifsallam\",\n        \"url\": \"https://api.github.com/users/seifsallam\"\n    },\n    \"created_at\": \"2015-04-28T16:00:00Z\",\n    \"id\": \"2761189792\",\n    \"payload\": {\n        \"before\": \"b0654ac2ccc6a0860587d118ca74e9af10fcac52\",\n        \"commits\": [\n            {\n                \"author\": {\n                    \"email\": \"73675debcd8a436be48ec22211dcf44fe0df0a64@ibotta.com\",\n                    \"name\": \"Ben Limmer\"\n                },\n                \"distinct\": true,\n                \"message\": \"Add Ember.run snippet\\n\\nBecause the run loop doesn't run automatically in test, a lot of times I need to insert a fun loop. This addition would be really handy!\",\n                \"sha\": \"bae7eabf1ba43afbdef4e6023de0a7939986d7f6\",\n                \"url\": \"https://api.github.com/repos/seifsallam/atom-ember-snippets/commits/bae7eabf1ba43afbdef4e6023de0a7939986d7f6\"\n            },\n            {\n                \"author\": {\n                    \"email\": \"73675debcd8a436be48ec22211dcf44fe0df0a64@ibotta.com\",\n                    \"name\": \"Ben Limmer\"\n                },\n                \"distinct\": true,\n                \"message\": \"Update README.md\",\n                \"sha\": \"ee48b87dc057e5828c854634b492b8075f0ad062\",\n                \"url\": \"https://api.github.com/repos/seifsallam/atom-ember-snippets/commits/ee48b87dc057e5828c854634b492b8075f0ad062\"\n            },\n            {\n                \"author\": {\n                    \"email\": \"b1c1d8736f20db3fb6c1c66bb1455ed43909f0d8@seifsallam.com\",\n                    \"name\": \"Seif Sallam\"\n                },\n                \"distinct\": true,\n                \"message\": \"Merge pull request #7 from blimmer/patch-1\\n\\nAdd Ember.run snippet\",\n                \"sha\": \"2ed06f3fe3ee7493a73831970353bbfe244dddfb\",\n                \"url\": \"https://api.github.com/repos/seifsallam/atom-ember-snippets/commits/2ed06f3fe3ee7493a73831970353bbfe244dddfb\"\n            }\n        ],\n        \"distinct_size\": 3,\n        \"head\": \"2ed06f3fe3ee7493a73831970353bbfe244dddfb\",\n        \"push_id\": 647057321,\n        \"ref\": \"refs/heads/master\",\n        \"size\": 3\n    },\n    \"public\": true,\n    \"repo\": {\n        \"id\": 21066180,\n        \"name\": \"seifsallam/atom-ember-snippets\",\n        \"url\": \"https://api.github.com/repos/seifsallam/atom-ember-snippets\"\n    },\n    \"type\": \"PushEvent\"\n}\n"
    }
   ],
   "source": [
    "cur = conn.cursor()\n",
    "cur.execute(\"SELECT event FROM timescaledb.public.ts_events LIMIT 1\")\n",
    "rows = cur.fetchall()\n",
    "import json\n",
    "parsed = json.loads(rows[0][0])\n",
    "print(json.dumps(parsed, indent=4, sort_keys=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
